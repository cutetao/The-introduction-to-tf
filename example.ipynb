#测试Python的try语句
import tensorflow as tf
hello=tf.constant("Hello,Tensorflow")
sess=tf.Session()
try:
    print(sess.run(hello))
finally:
    sess.close()
a=tf.constant(10.0)
sess=tf.Session()
print(sess.run(a))
sess.close()


tens1=tf.constant([1,2,3])
#通过上下文管理器，自动完成释放资源，推出后不必要cloae
with tf.Session() as sess:
    print(sess.run(tens1))

#将会话设为默认之后的语句执行
node1=tf.constant(3.0,tf.float32,name="node1")
node2=tf.constant(4.0,tf.float32,name="node2")
result=tf.add(node1,node2)
sess=tf.Session()
with sess.as_default():
    print(result.eval())


node1=tf.constant(3.0,tf.float32,name="node1")
node2=tf.constant(4.0,tf.float32,name="node2")
result=tf.add(node1,node2)
sess=tf.InteractiveSession()
print(result.eval())
sess.close()

a=tf.constant(0.6,name="a")
b=tf.constant(0.4,name="b")
c=tf.add(a,b,name="c")
sess=tf.InteractiveSession()
#c_value=sess.run(c)
print(c.eval())
sess.close

#变量操作需要初始化
node1=tf.Variable(3.0,tf.float32,name="node1")
node2=tf.Variable(4.0,tf.float32,name="node2")
result=tf.add(node1,node2,name="add")
sess=tf.Session()
init=tf.global_variables_initializer()
sess.run(init)
print(sess.run(result))
sess.close()

#利用assign分配函数给变量赋值
import tensorflow as tf
value=tf.Variable(0,name="value")
one=tf.constant(1)
new_value=tf.add(value,one)
update_value=tf.assign(value,new_value)
init=tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    for _ in range(10):
        sess.run(update_value)
        print(sess.run(value)
        
#Tensorflow数据流图优势：
并行计算快
分布式计算快
预编译优化
可移植性好
张量：某种相同数据类型的多维数组
tf.placeholder is 占位符，描述了数据的壳，需要外面数据填充
变量可以在数据流图过程中被改变，它会被动态分配内存，防止丢失。
tf.Variable本身是一个方法，返回值是一个变量；变量常驻内存，在每一次训练时不断更新其值
tf.Variable(<initial value>,name=<optional name>)
tf.matmul()是将变量作为输入的函数
定义只是描述了框架，需要会话来执行
W.assign()是一个赋值函数
tf.train.Saver可以将正在训练的参数保存，作为checkpoint文件，
创建——》初始化——》更新或者存储——》恢复——》更新
操作数据流图中的节点，数据流图是一种声明式的编程范式，操作是模型功能的实际载体
分为数据节点为数据的占位符操作、计算节点为无状态的计算或者控制操作、存储节点为有状态的节点操作
少使用逻辑控制
会话：提供了估算张量和执行操作的运行环境，他是发放计算任务的刻苦段，所有计算任务都有它连接的执行引擎完成
